# test_text_analyzer.py
"""
åŸºäºspaCyçš„æ–‡æœ¬åˆ†æå·¥å…·æµ‹è¯•è„šæœ¬
ç”¨äºéªŒè¯è‡ªå®šä¹‰å·¥å…·çš„åŠŸèƒ½
"""

import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append('/root/autodl-tmp/DEFAME')

def test_spacy_availability():
    """æµ‹è¯•spaCyå¯ç”¨æ€§"""
    print("ğŸ” æµ‹è¯•spaCyç¯å¢ƒ...")
    
    try:
        import spacy
        print(f"âœ… spaCyç‰ˆæœ¬: {spacy.__version__}")
        
        # æ£€æŸ¥å¯ç”¨æ¨¡å‹
        available_models = spacy.util.get_installed_models()
        if available_models:
            print(f"âœ… å¯ç”¨æ¨¡å‹: {available_models}")
        else:
            print("âš ï¸  æ²¡æœ‰é¢„è®­ç»ƒæ¨¡å‹ï¼Œå°†ä½¿ç”¨åŸºç¡€è‹±æ–‡å¤„ç†å™¨")
        
        # å°è¯•åŠ è½½æ¨¡å‹
        try:
            nlp = spacy.load("en_core_web_sm")
            print("âœ… æˆåŠŸåŠ è½½ en_core_web_sm æ¨¡å‹")
        except OSError:
            try:
                from spacy.lang.en import English
                nlp = English()
                print("âœ… ä½¿ç”¨spaCyåŸºç¡€è‹±æ–‡å¤„ç†å™¨")
            except Exception as e:
                print(f"âŒ spaCyåˆå§‹åŒ–å¤±è´¥: {e}")
                return False
        
        return True
        
    except ImportError as e:
        print(f"âŒ spaCyå¯¼å…¥å¤±è´¥: {e}")
        return False


def test_sentiment_analysis():
    """æµ‹è¯•æƒ…æ„Ÿåˆ†æåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•æƒ…æ„Ÿåˆ†æåŠŸèƒ½...")
    
    from defame.evidence_retrieval.tools.text_analyzer import TextAnalyzer, AnalyzeText
    
    tool = TextAnalyzer()
    
    test_cases = [
        ("This is a great and wonderful day! I love this amazing product.", "ç§¯æ"),
        ("This is terrible and awful. I hate this disappointing product.", "æ¶ˆæ"),
        ("The weather report indicates cloudy conditions today.", "ä¸­æ€§"),
        ("I'm absolutely thrilled with the fantastic results!", "ç§¯æ"),
        ("This is completely false and misleading information.", "æ¶ˆæ")
    ]
    
    for text, expected in test_cases:
        action = AnalyzeText(text=text, analysis_type="sentiment")
        result = tool.perform(action, summarize=True)
        
        print(f"\nğŸ“ æµ‹è¯•æ–‡æœ¬: {text[:50]}...")
        print(f"ğŸ“Š åˆ†æç»“æœ:\n{result.raw}")
        print(f"ğŸ’­ æ€»ç»“: {result.takeaways}")
        print(f"âœ… é¢„æœŸ: {expected}, å®é™…: {getattr(result.raw, 'sentiment_label', 'æœªçŸ¥')}")


def test_keyword_extraction():
    """æµ‹è¯•å…³é”®è¯æå–åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•å…³é”®è¯æå–åŠŸèƒ½...")
    
    from defame.evidence_retrieval.tools.text_analyzer import TextAnalyzer, AnalyzeText
    
    tool = TextAnalyzer()
    
    test_text = """
    Artificial intelligence and machine learning are transforming technology industries worldwide. 
    Deep learning algorithms enable advanced computer vision and natural language processing capabilities. 
    These revolutionary technologies are dramatically improving healthcare diagnostics, financial analysis, 
    and educational systems across the globe.
    """
    
    action = AnalyzeText(text=test_text, analysis_type="keywords")
    result = tool.perform(action, summarize=True)
    
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text.strip()[:100]}...")
    print(f"ğŸ“Š å…³é”®è¯æå–ç»“æœ:\n{result.raw}")
    print(f"ğŸ’­ æ€»ç»“: {result.takeaways}")


def test_entity_recognition():
    """æµ‹è¯•å®ä½“è¯†åˆ«åŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•å®ä½“è¯†åˆ«åŠŸèƒ½...")
    
    from defame.evidence_retrieval.tools.text_analyzer import TextAnalyzer, AnalyzeText
    
    tool = TextAnalyzer()
    
    test_text = """
    Contact Dr. John Smith at john.smith@university.edu or call 555-123-4567. 
    Visit our website at https://www.example.com for more information. 
    The conference is scheduled for December 25, 2024 in New York City. 
    The project budget is $50,000 and involves 100 participants.
    Apple Inc. and Microsoft Corporation are major technology companies.
    """
    
    action = AnalyzeText(text=test_text, analysis_type="entities")
    result = tool.perform(action, summarize=True)
    
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text.strip()[:100]}...")
    print(f"ğŸ“Š å®ä½“è¯†åˆ«ç»“æœ:\n{result.raw}")
    print(f"ğŸ’­ æ€»ç»“: {result.takeaways}")


def test_comprehensive_analysis():
    """æµ‹è¯•ç»¼åˆåˆ†æåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•ç»¼åˆåˆ†æåŠŸèƒ½...")
    
    from defame.evidence_retrieval.tools.text_analyzer import TextAnalyzer, AnalyzeText
    
    tool = TextAnalyzer()
    
    test_text = """
    BREAKING NEWS: Revolutionary breakthrough in artificial intelligence research! 
    Scientists at Stanford University have developed amazing machine learning algorithms 
    that could transform healthcare. Dr. Sarah Johnson (sarah.johnson@stanford.edu) 
    announced the fantastic results on January 15, 2024. The $2.5 million project 
    took 3 years to complete. Contact the research team at 650-555-0123. 
    This incredible advancement represents a major milestone in AI development!
    """
    
    action = AnalyzeText(text=test_text, analysis_type="all")
    result = tool.perform(action, summarize=True)
    
    print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text.strip()[:100]}...")
    print(f"ğŸ“Š ç»¼åˆåˆ†æç»“æœ:\n{result.raw}")
    print(f"ğŸ’­ æ€»ç»“: {result.takeaways}")


def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("\nğŸ” æµ‹è¯•é”™è¯¯å¤„ç†...")
    
    from defame.evidence_retrieval.tools.text_analyzer import AnalyzeText
    
    try:
        # æµ‹è¯•ç©ºæ–‡æœ¬
        empty_action = AnalyzeText(text="", analysis_type="sentiment")
        print("âŒ ç©ºæ–‡æœ¬æµ‹è¯•å¤±è´¥ - åº”è¯¥æŠ›å‡ºå¼‚å¸¸")
    except ValueError as e:
        print(f"âœ… ç©ºæ–‡æœ¬é”™è¯¯å¤„ç†æ­£ç¡®: {e}")
    
    try:
        # æµ‹è¯•æ— æ•ˆåˆ†æç±»å‹
        invalid_action = AnalyzeText(text="Test text", analysis_type="invalid")
        print("âŒ æ— æ•ˆç±»å‹æµ‹è¯•å¤±è´¥ - åº”è¯¥æŠ›å‡ºå¼‚å¸¸")
    except ValueError as e:
        print(f"âœ… æ— æ•ˆç±»å‹é”™è¯¯å¤„ç†æ­£ç¡®: {e}")


def test_spacy_features():
    """æµ‹è¯•spaCyç‰¹å®šåŠŸèƒ½"""
    print("\nğŸ” æµ‹è¯•spaCyç‰¹å®šåŠŸèƒ½...")
    
    from defame.evidence_retrieval.tools.text_analyzer import TextAnalyzer
    
    tool = TextAnalyzer()
    
    if tool.nlp:
        print("âœ… spaCyæ¨¡å‹å·²åŠ è½½")
        
        # æµ‹è¯•åŸºæœ¬NLPåŠŸèƒ½
        test_text = "Apple Inc. is planning to release new products in 2024."
        doc = tool.nlp(test_text)
        
        print(f"ğŸ“ æµ‹è¯•æ–‡æœ¬: {test_text}")
        print("ğŸ·ï¸  è¯æ€§æ ‡æ³¨:")
        for token in doc:
            if not token.is_space:
                print(f"  {token.text}: {token.pos_} ({token.lemma_})")
        
        print("ğŸ¢ å‘½åå®ä½“:")
        for ent in doc.ents:
            print(f"  {ent.text}: {ent.label_}")
            
    else:
        print("âš ï¸  spaCyæ¨¡å‹æœªåŠ è½½ï¼Œä½¿ç”¨åŸºç¡€åŠŸèƒ½")


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 70)
    print("ğŸš€ å¼€å§‹æµ‹è¯•åŸºäºspaCyçš„æ–‡æœ¬åˆ†æå·¥å…·")
    print("=" * 70)
    
    try:
        # é¦–å…ˆæµ‹è¯•spaCyç¯å¢ƒ
        spacy_ok = test_spacy_availability()
        
        # è¿è¡ŒåŠŸèƒ½æµ‹è¯•
        test_sentiment_analysis()
        test_keyword_extraction()
        test_entity_recognition()
        test_comprehensive_analysis()
        test_error_handling()
        
        if spacy_ok:
            test_spacy_features()
        
        print("\n" + "=" * 70)
        print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        print("=" * 70)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
